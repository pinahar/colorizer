{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named pydot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45c5a8c63c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ajeet/anaconda/lib/python2.7/site-packages/keras/utils/visualize_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Fall back on pydot if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     raise ImportError('Failed to import pydot. You must install pydot'\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pydot"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input \n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "import pprint\n",
    "import cPickle\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Merge, merge\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.utils.visualize_util import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        rescale=1./255,\n",
    "        dim_ordering='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for directory in os.listdir('./data/'):\n",
    "    l = os.listdir('./data/' + directory)\n",
    "    for image in l:\n",
    "        image = l[0]\n",
    "        img = load_img('./data/' + directory + '/' + image, target_size=(224,224))  # this is a PIL image\n",
    "        img = img.convert(\"YCbCr\")\n",
    "        x = img_to_array(img)\n",
    "        Y_train.append(x[:,:,1:])\n",
    "        X_train.append(x[:,:,:1])\n",
    "    break\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX_train = np.zeros((X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3] + 2))\n",
    "XX_train[:,:,:,0:] = X_train\n",
    "XX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    ''' \n",
    "        * return: compiled model (keras.engine.training.Model)\n",
    "    '''\n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    for i in range(9):\n",
    "        vgg_model.layers.pop()    \n",
    "    \n",
    "    bnl = BatchNormalization() (vgg_model.layers[-1].output)\n",
    "    cnl = Convolution2D(256, 1, 1, border_mode='same', dim_ordering='tf') (bnl)\n",
    "    usl = UpSampling2D(dim_ordering='tf') (cnl)\n",
    "    bnl = BatchNormalization() (vgg_model.layers[-5].output)\n",
    "    ml = merge([usl, bnl], mode='sum')\n",
    "    cnl = Convolution2D(128, 3, 3, border_mode='same', dim_ordering='tf') (ml)\n",
    "\n",
    "    usl = UpSampling2D(dim_ordering='tf') (cnl)\n",
    "    bnl = BatchNormalization() (vgg_model.layers[-9].output)\n",
    "    ml = merge([usl, bnl], mode='sum')\n",
    "    cnl = Convolution2D(64, 3, 3, border_mode='same', dim_ordering='tf') (ml)\n",
    "\n",
    "    usl = UpSampling2D(dim_ordering='tf') (cnl)\n",
    "    bnl = BatchNormalization() (vgg_model.layers[-12].output)\n",
    "    ml = merge([usl, bnl], mode='sum')\n",
    "    cnl = Convolution2D(3, 3, 3, border_mode='same', dim_ordering='tf') (ml)\n",
    "\n",
    "    bnl = BatchNormalization() (vgg_model.layers[-14].output)\n",
    "    ml = merge([cnl, bnl], mode='sum')\n",
    "    cnl = Convolution2D(3, 3, 3, border_mode='same', dim_ordering='tf') (ml)\n",
    "\n",
    "    cnl = Convolution2D(2, 3, 3, border_mode='same', dim_ordering='tf') (cnl)\n",
    "\n",
    "    tl_model = Model( input=vgg_model.input, output=cnl )\n",
    "    for i in range(1, 14):\n",
    "        tl_model.layers[i].trainable = False\n",
    "\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##loss function\n",
    "\n",
    "# def blur_uv_loss(rgb, inferred_rgb):\n",
    "#     uv = rgb2uv(rgb)\n",
    "#     uv_blur0 = rgb2uv(blur(rgb, 3))\n",
    "#     uv_blur1 = rgb2uv(blur(rgb, 5))\n",
    "\n",
    "#     inferred_uv = rgb2uv(inferred_rgb)\n",
    "#     inferred_uv_blur0 = rgb2uv(blur(inferred_rgb, 3))\n",
    "#     inferred_uv_blur1 = rgb2uv(blur(inferred_rgb, 5))\n",
    "\n",
    "#     return  ( dist(inferred_uv, uv) +\n",
    "#             dist(inferred_uv_blur0 , uv_blur0) +\n",
    "#             dist(inferred_uv_blur1, uv_blur1) ) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tl_model = getModel()\n",
    "# pprint.PrettyPrinter(indent=2).pprint(tl_model.get_config())\n",
    "tl_model.summary()\n",
    "\n",
    "tl_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# history = tl_model.fit_generator(train_datagen.flow(X_train,Y_train,batch_size=88), samples_per_epoch=88, nb_epoch=50, validation_data=(X_valid,Y_valid), verbose=1)\n",
    "\n",
    "history = tl_model.fit(XX_train[:10,:,:,:],Y_train[:10,:,:,:],batch_size=5, nb_epoch=100, verbose=1, shuffle=True)\n",
    "\n",
    "# tl_model.save(filepath='./output/urban_2_images')\n",
    "# cPickle.dump( history.history, open( \"urbnan_2_images.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tl_model.predict(XX_train[0:1, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = a.reshape(224,224,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = np.append(XX_train[0,:,:,0:1], a, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = Image.fromarray(i, mode='YCbCr').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = img_to_array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
